## Communication-Efficient Learning of Deep Networks from Decentralized Data

这篇应该是最先提出Federated Learning概念的论文(´･_･`)

> We advocate an alternative that leaves the training data distributed on the mobile devices, and learns a shared model by aggregating locally-computed updates. We term this decentralized approach **Federated Learning**.



### 1. Introduction

为了解决智能手机及平板电脑等移动设备上的分布式数据集的模型训练问题，文章提出了一种新的训练方法，称为联邦学习。因为训练任务是由一个中心服务器协调下的一群参与设备（称为客户端）的松散联邦组成。每个客户端本地的训练数据集都不上传给服务端，而是计算出对由服务端维护的全局模型的更新，并且只通信该更新。

此外关于联邦学习的背景和概念就不再赘述。



本文的主要内容是：

*  the identification of the problem of training on decentralized data from mobile devices as an important research direction。也即确定了解决去中心化数据的训练问题是联邦学习主要的研究方向。

* the selection of a straightforward and practical algorithm that can be applied to this setting。提出了一个基础的算法（也就是FederatedAveraging）。

* an extensive empirical evaluation of the proposed approach。对该算法的评估。

  具体地说，该算法将每个client上的SGD和执行model averaging的服务器相结合。证明了它对不平衡和non-IID数据是robust的。



#### Federated Learning

联邦学习的**理想问题**具有以下性质：

* 对**真实数据**（real-world）进行训练比在数据中心中的**代理数据**上进行训练具有明显的优势；
* 数据是**隐私敏感**或者**规模较大**的（相较于模型的规模）；
* 对于监督任务，数据的**label**可以从用户交互中自然**推断**出来。

举两个栗子，图像分类和语言模型。首先，这两个任务的数据（用户拍摄的照片或在键盘上的输入）是**隐私敏感**的（第二个性质）；这些例子所来自的分布也和可以很容易获得的代理数据集有很大不同（第一个性质，如聊天文本和标准语言语料库的区别，很显然从聊天文本来训练更有效）；最后，这些问题的**label**是直接可用的（输入的文本自我标记，而照片标签可以从用户与app的交互来定义，如哪些被删除，被分享）。



#### Federated Optimization

联邦学习场景下的优化问题有几个区别于分布式学习优化的关键性质：

* **Non-IID**。客户端上的训练数据通常是基于特定用户对设备的使用情况，因此任何特定用户的数据集不能代表整个分布。
* **Unbalanced**。顾名思义，有的用户使用设备多，那么数据就多。数据集之间不平衡。
* **Massively distributed**。预计参与优化的客户端数量远大于每个客户端的平均example数量。
* **Limited communication**。移动设备频繁的掉线或者连接速度慢，连接贵等。

本文优化的重点在于处理Non-IID，Unbalanced数据和通信的约束方面。

除此之外，还要解决一些实际问题：如随着数据添加或删除而改变的数据集；client在一些复杂情况下（跟数据集分布所相关的）的availability（比如使用美式英语和使用英式英语的人在不同时间段加入数据，此时client是否可用？）；以及不回复的client或者发送错误updates的client。



### 2. The FederatedAveraging Algorithm

随机梯度下降（SGD）算法应用广泛，并且可以直接应用到联邦学习的过程中。即每一轮训练，中心服务器都随机选取一批客户端，在这些客户端上面执行一次SGD计算，并将计算结果发回中心服务器做聚合。这种做法概念很清晰，但是为了将模型训练出良好的效果，需要进行巨量的计算。

作为改进，首先作者提出了**FederatedSGD**（或者**FedSGD**）。在每一轮训练中，选择C-fraction（C分之一的意思？(´･_･`)）的客户端，并计算这些客户端的所有数据的损失梯度。因此，C控制了golbal batch的大小（C=1就表示full-batck的梯度下降，此时非随机）。

然后就是**FederatedAveraging**（或者FedAvg）。具体做法是，每一轮训练中，在每个客户端上都执行多次计算，然后将计算结果做聚合。

直接看伪代码：

![image-20231016193832144](https://cdn.jsdelivr.net/gh/Changocc/img@img/pic/image-20231016193832144.png)

* $\omega$：训练的**模型参数**。
* $K$：**客户端的数量**。
* $C$：每一轮中进行计算的客户端**比例**。
* $S_t$：每一轮训练中，随机选取的m个**客户端**。
* $n_k$：每个客户端上的**数据量**。
* $n$：这些客户端上的**全部**的数据量。
* $B$：每个客户端上的本地数据**随机分成**B份，选取其中的一份进行训练。
* $E$：每轮训练中客户端**迭代的次数**。
* $\eta$：**学习率**。

具体地说：

每轮训练开始时，中心服务器随机选出$m$个客户端，将当前的模型参数$w_t$发给这些客户端。

在这些客户端上，将本地数据随机分成$B$份，选取其中一份，进行$E$次迭代训练，算出本地的$w_{t+1}^k$发送给中心服务器。中心服务器收到所有客户端发来的局部模型更新$w_t^{k+1}$之后，通过$\sum_{k=1}^K{n_k \over n}w_{t+1}^k$来进行聚合运算，计算出全局的模型更新$w_{t+1}$。

（当B取 ∞，E取1就是FedSGD）



### Experiment

还找不到源代码，后面复现的时候再更新吧。。(´･_･`)

对于图像识别任务，作者在MINST手写数据集上分别使用了2NN和CNN的训练模型。对于语言模型，作者在莎士比亚全集数据集上构建了模型。使用的是A stacked character-level LSTM语言模型。

* Experiment 1是增加并行度的实验，也就是增大C值。

* Experiment 2 是增加节点计算量的实验，减少B或者增加E。

  前两个都是通过提高计算时间在总时间的占比，减少通信时间的占比，缓解通信耗时的问题。

* Experiment 3 是更多地利用自己的数据，增大E值。

* Experiment 4 是CIFAR-10上的实验。

* Experiment 5 是使用 LSTM的实验。